install.packages(c("keras", "tensorflow"))
?install_keras
??install_keras
#cuDNN
# %USERPROFILE%\cuda
# %CUDA_Installation_directory%\bin\cudnn64_7.dll
# % CUDA_Installation_directory %\include\cudnn.h
# % CUDA_Installation_directory %\lib\x64\cudnn.lib
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA
library(keras)
?install_keras
# install.packages("keras")
install.packages("tensorflow")
install.packages("tensorflow")
library(tensorflow)
#GPU
# install_tensorflow(version = "gpu")
install_keras(tensorflow = "gpu")
#GPU
install_tensorflow(version = "gpu")
#cuDNN
# %USERPROFILE%\cuda
# %CUDA_Installation_directory%\bin\cudnn64_7.dll
# % CUDA_Installation_directory %\include\cudnn.h
# % CUDA_Installation_directory %\lib\x64\cudnn.lib
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1
# new setup
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin\
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\lib\x64
library(keras)
#GPU
install_tensorflow(version = "gpu")
#GPU
install_tensorflow(version = "gpu")
library(tensorflow)
#GPU
install_tensorflow(version = "gpu")
#cuDNN
# %USERPROFILE%\cuda
# %CUDA_Installation_directory%\bin\cudnn64_7.dll
# % CUDA_Installation_directory %\include\cudnn.h
# % CUDA_Installation_directory %\lib\x64\cudnn.lib
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1
# new setup
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin\
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\lib\x64
library(keras)
library(tensorflow)
#GPU
install_tensorflow(version = "gpu")
#CPU - work.
install_tensorflow()
#GPU
install_tensorflow(version = "gpu")
#cuDNN
# %USERPROFILE%\cuda
# %CUDA_Installation_directory%\bin\cudnn64_7.dll
# % CUDA_Installation_directory %\include\cudnn.h
# % CUDA_Installation_directory %\lib\x64\cudnn.lib
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1
# new setup
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin\
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\lib\x64
library(keras)
library(tensorflow)
#GPU
install_tensorflow(version = "gpu")
install_keras(tensorflow = "gpu")
####TEst#####
#Check available devices
library(keras)
# input layer: use MNIST images
mnist <- dataset_mnist()
library(tensorflow)
# input layer: use MNIST images
mnist <- dataset_mnist()
k<-backend()
sess <-k$get_session()
sess$list_devices()
####TEst#####
#Check available devices
library(keras)
use_condaenv("r-tensorflow")
()
()
# # use_condaenv("r-tensorflow")
k<-backend()
sess <-k$get_session()
sess$list_devices()
# input layer: use MNIST images
mnist <- dataset_mnist()
install_tensorflow()
install_keras()
install_keras()
####TEst#####
#Check available devices
library(keras)
# # use_condaenv("r-tensorflow")
k<-backend()
sess <-k$get_session()
sess$list_devices()
#GPU
# install_tensorflow(version = "gpu")
# install_keras(tensorflow = "gpu")
reticulate::use_condaenv("keras-gpu")
#GPU
# install_tensorflow(version = "gpu")
install_keras(tensorflow = "gpu")
#GPU
# install_tensorflow(version = "gpu")
install_keras(tensorflow = "gpu")
reticulate::use_condaenv("keras-gpu")
#cuDNN
# %USERPROFILE%\cuda
# %CUDA_Installation_directory%\bin\cudnn64_7.dll
# % CUDA_Installation_directory %\include\cudnn.h
# % CUDA_Installation_directory %\lib\x64\cudnn.lib
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1
# new setup
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin\
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\lib\x64
library(keras)
library(tensorflow)
install_keras(tensorflow = "gpu")
#cuDNN
# %USERPROFILE%\cuda
# %CUDA_Installation_directory%\bin\cudnn64_7.dll
# % CUDA_Installation_directory %\include\cudnn.h
# % CUDA_Installation_directory %\lib\x64\cudnn.lib
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1
# new setup
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin\
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\lib\x64
library(keras)
library(tensorflow)
#GPU
install_keras(tensorflow = "gpu")
reticulate::use_condaenv("keras-gpu")
#cuDNN
# %USERPROFILE%\cuda
# %CUDA_Installation_directory%\bin\cudnn64_7.dll
# % CUDA_Installation_directory %\include\cudnn.h
# % CUDA_Installation_directory %\lib\x64\cudnn.lib
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1
# new setup
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin\
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\lib\x64
library(keras)
library(tensorflow)
#GPU
reticulate::use_condaenv("keras-gpu")
install_tensorflow(version = "gpu")
#cuDNN
# %USERPROFILE%\cuda
# %CUDA_Installation_directory%\bin\cudnn64_7.dll
# % CUDA_Installation_directory %\include\cudnn.h
# % CUDA_Installation_directory %\lib\x64\cudnn.lib
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1
# new setup
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin\
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\lib\x64
library(keras)
library(tensorflow)
#GPU
# reticulate::use_condaenv("keras-gpu")
install_tensorflow(version = "gpu")
install_keras(tensorflow = "gpu")
?reticulate
#cuDNN
# %USERPROFILE%\cuda
# %CUDA_Installation_directory%\bin\cudnn64_7.dll
# % CUDA_Installation_directory %\include\cudnn.h
# % CUDA_Installation_directory %\lib\x64\cudnn.lib
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1
# new setup
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin\
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\lib\x64
library(keras)
library(tensorflow)
####TEst#####
#Check available devices
library(keras)
# # use_condaenv("r-tensorflow")
k<-backend()
reticulate::use_condaenv("tf_gpu")
reticulate::conda_list()
#GPU
reticulate::use_condaenv("r-tensorflow")
reticulate::use_condaenv(" ANACON~1")
#GPU
reticulate::use_condaenv()
reticulate::conda_list()
#Text Generation####
#Creating the corpus
library(keras)
library(stringr)
path <- get_file(
"nietzsche.txt",
origin = "https://s3.amazonaws.com/text-datasets/nietzsche.txt"
)
text <- tolower(readChar(path, file.info(path)$size))
cat("Corpus length:", nchar(text), "\n")
#Text Generation####
#Creating the corpus
library(keras)
library(stringr)
maxlen <- 60  # Length of extracted character sequences
maxlen <- 60  # Length of extracted character sequences
step <- 3  # We sample a new sequence every `step` characters
text_indexes <- seq(1, nchar(text) - maxlen, by = step)
path <- get_file(
"nietzsche.txt",
origin = "https://s3.amazonaws.com/text-datasets/nietzsche.txt"
)
text <- tolower(readChar(path, file.info(path)$size))
cat("Corpus length:", nchar(text), "\n")
use_condaenv("base")
path <- get_file(
"nietzsche.txt",
origin = "https://s3.amazonaws.com/text-datasets/nietzsche.txt"
)
####TEst#####
#Check available devices
library(keras)
install.packages("keras")
install.packages("keras")
install.packages("tensorflow")
#cuDNN
# %USERPROFILE%\cuda
# %CUDA_Installation_directory%\bin\cudnn64_7.dll
# % CUDA_Installation_directory %\include\cudnn.h
# % CUDA_Installation_directory %\lib\x64\cudnn.lib
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1
# new setup
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin\
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp
# C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\lib\x64
library(keras)
library(tensorflow)
install_tensorflow(version = "gpu")
# install_tensorflow(version = "gpu")
install_keras(tensorflow = "gpu")
####TEst#####
#Check available devices
library(keras)
####TEst#####
#Check available devices
library(keras)
# # use_condaenv("base")
k<-backend()
sess <-k$get_session()
sess$list_devices()
# input layer: use MNIST images
mnist <- dataset_mnist()
x_train <- mnist$train$x; y_train <- mnist$train$y
x_test <- mnist$test$x; y_test <- mnist$test$y
# reshape and rescale
x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
x_train <- x_train / 255; x_test <- x_test / 255
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
# defining the model and layers
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = 'relu',
input_shape = c(784)) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
# compile (define loss and optimizer)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
# train (fit)
model %>% fit(
x_train, y_train,
epochs = 5, batch_size = 128,
validation_split = 0.2
)
#Text Generation####
#Creating the corpus
library(keras)
library(stringr)
#use_condaenv("base")
path <- get_file(
"nietzsche.txt",
origin = "https://s3.amazonaws.com/text-datasets/nietzsche.txt"
)
text <- tolower(readChar(path, file.info(path)$size))
cat("Corpus length:", nchar(text), "\n")
maxlen <- 60  # Length of extracted character sequences
step <- 3  # We sample a new sequence every `step` characters
text_indexes <- seq(1, nchar(text) - maxlen, by = step)
# This holds our extracted sequences
sentences <- str_sub(text, text_indexes, text_indexes + maxlen - 1)
# This holds the targets (the follow-up characters)
next_chars <- str_sub(text, text_indexes + maxlen, text_indexes + maxlen)
cat("Number of sequences: ", length(sentences), "\n")
# List of unique characters in the corpus
chars <- unique(sort(strsplit(text, "")[[1]]))
cat("Unique characters:", length(chars), "\n")
# Dictionary mapping unique characters to their index in `chars`
char_indices <- 1:length(chars)
names(char_indices) <- chars
# Next, one-hot encode the characters into binary arrays.
cat("Vectorization...\n")
x <- array(0L, dim = c(length(sentences), maxlen, length(chars)))
y <- array(0L, dim = c(length(sentences), length(chars)))
for (i in 1:length(sentences)) {
sentence <- strsplit(sentences[[i]], "")[[1]]
for (t in 1:length(sentence)) {
char <- sentence[[t]]
x[i, t, char_indices[[char]]] <- 1
}
next_char <- next_chars[[i]]
y[i, char_indices[[next_char]]] <- 1
}
#Initiliaize the model again if needed
# model <- keras_model_sequential() %>%
#   layer_lstm(units = 128, input_shape = c(maxlen, length(chars))) %>%
#   layer_dense(units = length(chars), activation = "softmax")
#
#
# optimizer <- optimizer_rmsprop(lr = 0.01)
# model %>% compile(
#   loss = "categorical_crossentropy",
#   optimizer = optimizer
# )
#Load the model after the first iteration
model<-load_model_hdf5("Nizhe.h5", custom_objects = NULL, compile = TRUE)
library(tidyverse)
library(tidyverse)
Data<-read_csv("data.csv")
BestJumper<-Data[Data$`Broad Jump`>1.56*sd(Data$`Broad Jump`)+mean(Data$`Broad Jump`)  ,]
BestJumper$Name
DataScaled<-scale(
Data%>%
select(-Methodology,-Name)
)
# Libraries
library(tidyverse)
library(Hmisc)
library(ggthemes)
library(stringr)
library(GGally)
library(stringr)
library(hrbrthemes)
# install.packages('hrbrthemes')
Data<-read_csv("data.csv")
BestJumper<-Data[Data$`Broad Jump`>1.56*sd(Data$`Broad Jump`)+mean(Data$`Broad Jump`)  ,]
BestJumper$Name
DataScaled<-scale(
Data%>%
select(-Methodology,-Name)
)
Data<-read_csv("data.csv")
setwd("D:/Work/PhDIvanSimeonov/R")
Data<-read_csv("data.csv")
BestJumper<-Data[Data$`Broad Jump`>1.56*sd(Data$`Broad Jump`)+mean(Data$`Broad Jump`)  ,]
BestJumper$Name
DataScaled<-scale(
Data%>%
select(-Methodology,-Name)
)
DataScaled$Name <- Data$Name
DataScaled$`4x10m shuttle`
DataScaled
Data%>%
select(-Methodology,-Name)
scale(
Data%>%
select(-Methodology,-Name)
)
Data
